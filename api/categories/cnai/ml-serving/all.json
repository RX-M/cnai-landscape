[{"category":"CNAI","homepage_url":"https://kserve.github.io/website/0.11/","id":"cnai--ml-serving--kserve","logo_url":"http://127.0.0.1:8000/logos/c15e376e2f22f76445c233b8bd51d34e40c32e62e009cb8044dd4f2baf8e7c4a.svg","name":"Kserve","subcategory":"ML Serving","description":"Highly scalable and standards based Model Inference Platform on Kubernetes for Trusted AI","repositories":[{"url":"https://github.com/kserve/kserve","primary":true}]},{"category":"CNAI","homepage_url":"https://www.seldon.io/","id":"cnai--ml-serving--seldon","logo_url":"http://127.0.0.1:8000/logos/1a2408c0e35353633945ab78368c93d6342dffb8102276c912b28bf0a13e2512.svg","name":"Seldon","subcategory":"ML Serving","repositories":[{"url":"https://github.com/SeldonIO/seldon-core","primary":true}]},{"category":"CNAI","homepage_url":"https://huggingface.co/docs/text-generation-inference/index","id":"cnai--ml-serving--text-generation-inference-tgi","logo_url":"http://127.0.0.1:8000/logos/795826da1f89fa2f05e72ce9f4e3c135c473edc16bdc83f716107d9c7f34546f.svg","name":"text-generation-inference (TGI)","subcategory":"ML Serving","description":"Large Language Model Text Generation Inference","repositories":[{"url":"https://github.com/huggingface/text-generation-inference","primary":true}]},{"category":"CNAI","homepage_url":"https://docs.vllm.ai/en/latest/","id":"cnai--ml-serving--vllm","logo_url":"http://127.0.0.1:8000/logos/f6f7df61e7998b6b4a1a04fac8a611065bca3552b9c1cd92115413c8c4afe2a4.svg","name":"vLLM","subcategory":"ML Serving","description":"vLLM is a fast and easy-to-use library for LLM inference and serving.","repositories":[{"url":"https://github.com/vllm-project/vllm","primary":true}]}]