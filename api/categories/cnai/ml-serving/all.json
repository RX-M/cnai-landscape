[{"category":"CNAI","homepage_url":"https://kserve.github.io/website/0.11/","id":"cnai--ml-serving--kserve","logo_url":"http://127.0.0.1:8000/logos/58b98f77df62fd32543239f3890d5a71f3a252c609892c744d7eb329b9f78b43.svg","name":"Kserve","subcategory":"ML Serving","description":"Highly scalable and standards based Model Inference Platform on Kubernetes for Trusted AI","repositories":[{"url":"https://github.com/kserve/kserve","primary":true}]},{"category":"CNAI","homepage_url":"https://www.seldon.io/","id":"cnai--ml-serving--seldon","logo_url":"http://127.0.0.1:8000/logos/58b98f77df62fd32543239f3890d5a71f3a252c609892c744d7eb329b9f78b43.svg","name":"Seldon","subcategory":"ML Serving","repositories":[{"url":"https://github.com/SeldonIO/seldon-core","primary":true}]},{"category":"CNAI","homepage_url":"https://huggingface.co/docs/text-generation-inference/index","id":"cnai--ml-serving--text-generation-inference-tgi","logo_url":"http://127.0.0.1:8000/logos/58b98f77df62fd32543239f3890d5a71f3a252c609892c744d7eb329b9f78b43.svg","name":"text-generation-inference (TGI)","subcategory":"ML Serving","description":"Large Language Model Text Generation Inference","repositories":[{"url":"https://github.com/huggingface/text-generation-inference","primary":true}]},{"category":"CNAI","homepage_url":"https://docs.vllm.ai/en/latest/","id":"cnai--ml-serving--vllm","logo_url":"http://127.0.0.1:8000/logos/58b98f77df62fd32543239f3890d5a71f3a252c609892c744d7eb329b9f78b43.svg","name":"vLLM","subcategory":"ML Serving","description":"vLLM is a fast and easy-to-use library for LLM inference and serving.","repositories":[{"url":"https://github.com/vllm-project/vllm","primary":true}]}]